import pandas as pd
from textblob import TextBlob

# Sample data
data = {
    'comments': [
        "I love this product!",
        "This is the worst experience I've ever had.",
        "It's okay, not great but not bad.",
        "Absolutely fantastic!",
        "I wouldn't recommend this to anyone.",
        "Just average, nothing special."
    ]
}

# Create DataFrame
df = pd.DataFrame(data)

# Function to determine sentiment
def get_sentiment(comment):
    analysis = TextBlob(comment)
    if analysis.sentiment.polarity > 0:
        return 'Positive'
    elif analysis.sentiment.polarity < 0:
        return 'Negative'
    else:
        return 'Neutral'

# Apply sentiment analysis
df['sentiment'] = df['comments'].apply(get_sentiment)

# Display results
print(df)



# Lets Try to see if we can apply this real world code and make it work to our liking
import requests
from bs4 import BeautifulSoup
from textblob import TextBlob

# Step 1: Scrape text data from a website
url = 'https://facebook.com'  # Replace with your target website

# Fetch the content of the webpage
response = requests.get(url)

# Parse the webpage content with BeautifulSoup
soup = BeautifulSoup(response.content, 'html.parser')

# Extract text from a specific HTML tag, like all paragraph tags
paragraphs = soup.find_all('p')

# Combine all the paragraph texts into one block of text
text_content = ' '.join([p.get_text() for p in paragraphs])

# Step 2: Analyze the sentiment of the scraped text
blob = TextBlob(text_content)
sentiment = blob.sentiment

# Output the sentiment analysis results
print(f"Sentiment: {sentiment}")


# Code Addition: 16/09/2024 11:40
# Real-time Sentiment Analysis for Social Media Comments

import tweepy
from textblob import TextBlob
from flask import Flask, request, jsonify
import requests

app = Flask(__name__)

# Twitter API credentials
TWITTER_API_KEY = 'your_twitter_api_key'
TWITTER_API_SECRET = 'your_twitter_api_secret'
TWITTER_ACCESS_TOKEN = 'your_twitter_access_token'
TWITTER_ACCESS_TOKEN_SECRET = 'your_twitter_access_token_secret'

# Facebook and Instagram API credentials
FACEBOOK_ACCESS_TOKEN = 'your_facebook_access_token'
INSTAGRAM_ACCESS_TOKEN = 'your_instagram_access_token'

# Twitter authentication
auth = tweepy.OAuthHandler(TWITTER_API_KEY, TWITTER_API_SECRET)
auth.set_access_token(TWITTER_ACCESS_TOKEN, TWITTER_ACCESS_TOKEN_SECRET)
api = tweepy.API(auth)

def analyze_sentiment(text):
    analysis = TextBlob(text)
    return analysis.sentiment.polarity

@app.route('/analyze_twitter', methods=['GET'])
def analyze_twitter():
    tweets = api.user_timeline(screen_name='your_twitter_handle', count=10)
    sentiments = {tweet.text: analyze_sentiment(tweet.text) for tweet in tweets}
    return jsonify(sentiments)

@app.route('/analyze_facebook', methods=['GET'])
def analyze_facebook():
    url = f'https://graph.facebook.com/v12.0/me/feed?access_token={FACEBOOK_ACCESS_TOKEN}'
    response = requests.get(url)
    posts = response.json().get('data', [])
    sentiments = {post['message']: analyze_sentiment(post['message']) for post in posts if 'message' in post}
    return jsonify(sentiments)

@app.route('/analyze_instagram', methods=['GET'])
def analyze_instagram():
    url = f'https://graph.instagram.com/me/media?fields=id,caption&access_token={INSTAGRAM_ACCESS_TOKEN}'
    response = requests.get(url)
    posts = response.json().get('data', [])
    sentiments = {post['caption']: analyze_sentiment(post['caption']) for post in posts if 'caption' in post}
    return jsonify(sentiments)

if __name__ == '__main__':
    app.run(debug=True)


#NEW CODE FOR SENTIMENT ANALYSIS.
pip install nltk
import re
import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
import seaborn as sns
import string
import nltk
import warnings 
warnings.filterwarnings("ignore", category=DeprecationWarning)

%matplotlib inline

train = pd.read_csv('https://raw.githubusercontent.com/dD2405/Twitter_Sentiment_Analysis/master/train.csv')

train_original=train.copy()

test = pd.read_csv('https://raw.githubusercontent.com/dD2405/Twitter_Sentiment_Analysis/master/test.csv')

test_original=test.copy()

combine = train.append(test,ignore_index=True,sort=True)
def remove_pattern(text,pattern):
    
    # re.findall() finds the pattern i.e @user and puts it in a list for further task
    r = re.findall(pattern,text)
    
    # re.sub() removes @user from the sentences in the dataset
    for i in r:
        text = re.sub(i,"",text)
    
    return text
combine['Tidy_Tweets'] = np.vectorize(remove_pattern)(combine['tweet'], "@[\w]*")

combine.head()
combine['Tidy_Tweets'] = combine['Tidy_Tweets'].str.replace("[^a-zA-Z#]", " ")

combine.head(10)
combine['Tidy_Tweets'] = combine['Tidy_Tweets'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))

combine.head(10)
tokenized_tweet = combine['Tidy_Tweets'].apply(lambda x: x.split())

tokenized_tweet.head()
from nltk import PorterStemmer

ps = PorterStemmer()

tokenized_tweet = tokenized_tweet.apply(lambda x: [ps.stem(i) for i in x])

tokenized_tweet.head()
for i in range(len(tokenized_tweet)):
    tokenized_tweet[i] = ' '.join(tokenized_tweet[i])

combine['Tidy_Tweets'] = tokenized_tweet
combine.head()

#Visualizing of the sentiments
pip install wordcloud
from wordcloud import WordCloud,ImageColorGenerator
from PIL import Image
import urllib
import requests

all_words_positive = ' '.join(text for text in combine['Tidy_Tweets'][combine['label']==0])

pip install --upgrade Pillow

# combining the image with the dataset
Mask = np.array(Image.open(requests.get('http://clipart-library.com/image_gallery2/Twitter-PNG-Image.png', stream=True).raw))

# We use the ImageColorGenerator library from Wordcloud 
# Here we take the color of the image and impose it over our wordcloud
image_colors = ImageColorGenerator(Mask)

# Now we use the WordCloud function from the wordcloud library 
wc = WordCloud(background_color='black', height=1500, width=4000,mask=Mask).generate(all_words_positive)

# Size of the image generated 
plt.figure(figsize=(30,40))

# Here we recolor the words from the dataset to the image's color
# recolor just recolors the default colors to the image's blue color
# interpolation is used to smooth the image generated 
plt.imshow(wc.recolor(color_func=image_colors),interpolation="hamming")

plt.axis('off')
plt.show()


all_words_negative = ' '.join(text for text in combine['Tidy_Tweets'][combine['label']==1])

# combining the image with the dataset
Mask = np.array(Image.open(requests.get('http://clipart-library.com/image_gallery2/Twitter-PNG-Image.png', stream=True).raw))

# We use the ImageColorGenerator library from Wordcloud 
# Here we take the color of the image and impose it over our wordcloud
image_colors = ImageColorGenerator(Mask)

# Now we use the WordCloud function from the wordcloud library 
wc = WordCloud(background_color='black', height=1500, width=4000,mask=Mask).generate(all_words_negative)

# Size of the image generated 
plt.figure(figsize=(30,40))

# Here we recolor the words from the dataset to the image's color
# recolor just recolors the default colors to the image's blue color
# interpolation is used to smooth the image generated 
plt.imshow(wc.recolor(color_func=image_colors),interpolation="gaussian")

plt.axis('off')
plt.show()
